# NPU Workflow (High-Level)

## Purpose
This document defines the end-to-end execution order for NPU development and
evaluation inside RTLGen.

## Current status
- **Implemented**: RTL functional simulation path (MMIO/CQ/DMA + AXI memory model).
- **Implemented**: mapper descriptor generation and binary stream emission.
- **Implemented**: performance simulation with RTL/perf comparison helpers.
- **Implemented**: block-level OpenROAD wrapper flow and fp16 backend sweep harness.
- **Implemented**: fp16 backend finish-level comparison run
  (`builtin_raw16` vs `cpp_ieee`) with recommendation report.
- **Implemented**: `arch v0.2-draft` schema + `to_rtlgen` derivation path for
  compute (`gemm`/`vec`) candidate generation.

## 1) Define architecture config
- Create/edit architecture YAML under `npu/arch/examples/`.
- Validate with:
  `python3 npu/arch/validate.py <schema.yml> <arch.yml>`.
- Keep descriptor-facing fields aligned with `npu/shell/spec.md`.
- Layering policy:
  - architecture config captures top-level intent and search-space bounds,
  - rtlgen config is a derived per-run candidate generated by optimizer policy
    and history.
- See draft direction: `npu/docs/arch_v0_2_draft.md`.

## 2) Generate RTL
- Derive rtlgen JSON from architecture:
  `python3 npu/arch/to_rtlgen.py <arch.yml> --out <rtlgen.json>`.
  - Schema is auto-selected from `schema_version` (`0.1` or `0.2-draft`).
- Run generator from `npu/rtlgen/` to emit top RTL and generated maps:
  - `top.v`
  - `mmio_map.vh`
  - `sram_map.vh`
- For fp16 GEMM, default backend is now `compute.gemm.mac_source=rtlgen_cpp`
  when `compute.gemm.mac_type=fp16` unless explicitly overridden.

## 3) Build descriptors from mapper
- Use `npu/mapper/run.py` with schedule IR (`npu/mapper/ir.md`) to emit:
  - YAML descriptor dump (`--out`)
  - binary descriptor stream (`--out-bin`)
- Golden schedules and binaries are in `npu/mapper/examples/`.

## 4) Run RTL functional validation
- Use `npu/sim/rtl/Makefile` targets for shell, DMA, GEMM, and VEC checks.
- Use `npu/sim/run_golden.sh` for repeatable mixed/GEMM/VEC regressions.
- Capture logs for parity checks:
  - `GEMM_TIMING ...`
  - `VEC_DONE ...`

## 5) Run performance simulation and parity checks
- Run perf simulator on descriptor binaries:
  `python3 npu/sim/perf/run.py --bin <desc.bin> --out <trace.json> --summary`.
- Compare RTL/perf outputs:
  - `npu/sim/compare_gemm_timing.py`
  - `npu/sim/compare_compute_results.py`
- Keep model knobs in sync with backend policy in `npu/sim/perf/README.md`.

## 6) Run block-level synthesis (OpenROAD)
- Use `npu/synth/run_block_sweep.py` for generic block sweeps.
- Use `npu/synth/run_fp16_backend_sweep.py` for fp16 backend decisions:
  - sweep config: `npu/synth/fp16_backend_sweep_nangate45.json`
  - decision report: `runs/designs/npu_blocks/fp16_backend_decision_nangate45.md`
- Store append-only results under `runs/designs/`.

## 7) Aggregate results and iterate
- Track result rows in per-design `metrics.csv`.
- Keep run-level artifacts in `work/<hash>/result.json`.
- Update `npu/docs/status.md` and affected plan docs after milestone runs.

## Data management expectations
- Use unique run directories and preserve prior metrics rows.
- Record config hashes and parameter JSON for reproducibility.
- Keep generated design artifacts under `runs/designs/` (not hand-edited).

## Next steps
- Add compute-enabled non-fp16 block sweep runbooks (DMA/CQ + GEMM/VEC variants).
- Integrate C++ MAC `pp_row_feedback` backend option into generator and sweep it.
- Expand constrained-random compute parity coverage (especially fp16/vector derivatives).
- Harden v0.2 validation and extend derivation to include interconnect/mapping
  constraints in downstream mapper/perf policy.
